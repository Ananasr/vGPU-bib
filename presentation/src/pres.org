#+TITLE: Virtualisation de GPU
#+AUTHOR: Hedi Nasr
#+EMAIL: hedi.nasr@etu.univ-lyon1.fr
#+LANGUAGE: fr

#+STARTUP: beamer
#+OPTIONS: H:2
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: JuanLesPins
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_HEADER:

# L'idée général de la présentation n'est pas de présenter en détail les
# techniques de virtualisations de GPU, ni de faire un résumé de la recherche
# bibliographique, mais plûtot d'expliquer pourquoi le GPU est un élément
# indispensable pour le HPC de manière général. 
# Il s'agira aussi d'expliquer (dans un deuxième point) un élément capital
# dans la virtualisation de GPU : l'IOMMU / VT-D

* Introduction
  # Faire un rappel sur le contexte actuelle qui à mené à faire une recherche
  # sur le sujet. Prendre ensuite du recul par rapport au contexte
  # pour avoir une vue plus générale.
** Contexte
   École Normale Supérieure, 13 000 vidéos, cluster OAR.
** De manière plus générale
   Les applications d'aujourd'hui sont de plus en plus des applications
   multimédias (audio, vidéo, jeu-vidéo)
* Objectifs
** Gain en performance
   Amélioration des performances du processus de transcodage vidéo.
** Faible coût
   Montrer qu'avec un faible investissement, on obtient des performances de
   l'ordre de 2 à 100 fois par rapport au CPU classique.
* Environnement
  # On détaillera dans cette partie l'architecture répartis du
  # cluster de calculs pour le transcodage vidéo.
  # On proposera, par la suite, les techniques de virtualisations de GPU
  # les plus adaptés à notre archi.
** Xen
   Paravirtualisateur open-source. Technologie éprouvée et reconnue (Amazon EC2)
** OAR
   OAR est un gestionnaire de tâches et de ressources pour les infrastructures réparties.
** ffmpeg
   Logiciel de transcodage vidéo pouvant utiliser l'accéleration matérielle pour augmenter la
   rapidité du transcodage.
** Architecture 
   [[../images/ens.png]]
* Solutions
** GPU
   Microprocesseur massivement parallèle conçu pour accélérer les performances des applications
   graphiques.
** Architecture du GPU (1/2)
   - Des milliers de coeurs exécutant une seule instruction (à un instant =t=)
     sur un même jeu de donnée, en parallèle.
   - Débit mémoire très rapide (jusqu'à 480 Go/s)
    
*** NVidia Pascal

    | Opérations virgules flottantes | Vitesse       |
    |--------------------------------+---------------|
    | /double precision/ (64 bits)   | *5.3 TFLOPS*  |
    | /single precision/ (32 bits)   | *10.6 TFLOPS* |
    | /half precision/ (16 bits)     | *21.2 TFLOPS* |

** Architecture du GPU (2/2)
*** Composants principaux
    - Mémoire
      + la "RAM" du GPU
      + accessible par le GPU *et* le CPU
      + jusqu'à 16Go par GPU
      + débit allant jusqu'à
    - /Streaming Multiprocessors/ - SMs
      + unités de calculs
** Simple Processing Flow
   - Copie les données de la mémoire du CPU vers la mémoire du GPU
   - Charge le programme et l'exécute
   - Copie les résultats du GPU vers le CPU

   
   #+CAPTION: Workflow d'exécution GPU. Source: NVidia
   #+ATTR_LaTeX: :width 200
  [[../images/Data-flow.png]]

** NVLink
   Nouvelle technologie proposer par NVidia pour interconnectés ces GPUs en ne passant plus
   par le bus PCI Express. Les débits peuvent atteindre jusqu'à 160 Go/s en full-duplex (contre 16 Go/s
   pour le PCI Express).
     
** API
*** General-Purpose Computing
    *Objectif*: utiliser le GPU pour des calculs non graphiques (/deep-learning/, bio-chimie, transcodage vidéo, etc...).
    Panoplie d'outils *developer friendly* permettant le développement d'applications sur GPU:
    - Bibliothèques numériques
      + MATLAB, Mathematica
    - Debuggers et profilers
      + cuda-gdb
      + Visual Studio
    - Compilateur GPU
      + C
      + C++
      + Python
    - Outils de parallélisme
      - OpenACC
      - OpenMP
*** Compute Unified Device Architecture (CUDA) :B_frame:
    :PROPERTIES:
    :BEAMER_env: frame
    :BEAMER_envargs: [t]
    :END:
    
**** SIMT - Nomenclature
     :PROPERTIES:
     :BEAMER_col: 0.4
     :BEAMER_env: block
     :END:
    - *Thread*: unité d'exécution
     # + tous les threads exécute le même programme séquentiel
     # + les threads s'exécutent en parallèle
    - *Block*: un groupe de threads
     # + les blocks ont accès à la mémoire globale du GPU
    - *Grid*: composition de blocks
   
      
    Le développeur écris un =kernel= et décide du nombre total de threads
    qui vont exécuter le programme sur le GPU.
**** CUDA architecture
     :PROPERTIES:
     :BEAMER_col: 0.46
     :BEAMER_env: block
     :BEAMER_envargs: <2->
     :END:
     
     #+CAPTION: Modèle d'exécution. Source: NVidia
     [[../images/cuda.png]]
  
*** Open Computing Language (OpenCL) :B_frame:
    :PROPERTIES:
    :BEAMER_env: frame
    :BEAMER_envargs: [t]
    :END:
**** SIMT - Nomenclature
     :PROPERTIES:
     :BEAMER_col: 0.45
     :BEAMER_env: block
     :END:
     - *Work Item*: un thread
     - *Work Group*: un groupe de 64 workitems
     - *NDRange*: composition de workgroups

**** OpenCL architecture
     :PROPERTIES:
     :BEAMER_col: 0.5
     :BEAMER_env: block
     :BEAMER_envargs: <2->
     :END:

     #+CAPTION: Modèle d'exécution. Source: http://mygsoc.blogspot.fr/2013/07/opencl-framework.html
     [[../images/opencl.png]]
  
** OpenACC
   Outil de compilation parallèle sur GPU. Ressemble à OpenMP.
   Gain de performance significatif. Ne modifie que
   très peu le code. Permet l'utilisation de la *mémoire unifiée* (mémoire GPU + RAM).
   # Mais code source fermé, utilisation soumis à licence propriétaire.
   # (usage académique gratuit).
   
   #+CAPTION: Source: NVidia
   [[../images/openacc.png]]
    
*** OpenMP - CPU
    :PROPERTIES:
    :BEAMER_env: frame
    :END:
    #+BEGIN_SRC c
    void vecadd(int n, float *c,
                 const float *a, const float* b)
     {
       #pragma omp parallel for
       for (int i = 0; i < n; i++)
         c[i] = a[i] + b[i];
     }
    #+END_SRC

*** OpenACC - GPU
    :PROPERTIES:
    :BEAMER_env: frame
    :END:
    #+BEGIN_SRC c
     void vecadd(int n, float *c,
                 const float *a, const float* b)
     {
       #pragma acc parallel loop
       for (int i = 0; i < n; i++)
         c[i] = a[i] + b[i];
     }
   #+END_SRC
* Techniques de virtualisation de GPU
** Pourquoi virtualiser les GPU ?
*** Virtual Desktop Infrastructure
    - Xen Desktop
    - VMWare Horizon
*** SaaS
    - AutoCAD - Autodesk
    - Photoshop - Adobe
*** IaaS
    - Amazon EC2
*** Cloud Gaming
    - Gaikai
    - Liquidsky
** Plusieurs techniques
*** Direct pass-through
    Instructions I/O-MMU et VT-D.
    Performances natives du GPU.
    Tous les hyperviseurs proposent cette méthode.
*** API Interception
    - vCUDA (VMRPC)
    - rCUDA (TCP/IP, API Socket)
    - gVim (Xen)
** Comparaison
   
* Conclusion
** Conclusion
   Il existe différentes architectures de GPU et différentes techniques pour les virtualiser.
   Plusieurs API peuvent les utiliser afin de bénéficier de leurs puissances de calculs.
   Le GPU est donc devenu un élément indispensable pour le /High Performance Computing/.
* Questions ?
** Avez-vous des questions ?
   
